<app-blog-post
    [postTitle]="postTitle()"
    [postDate]="postDate()"
    [postAbstract]="postAbstract()">

    <h3>Why use Docker?</h3>

    <p>In today's world more and more applications become Dockerized, thanks to its ability to
        provide consistent behavior across multiple platforms. That means if you deploy a Docker image with version
        1.0.0 on your test environment, then you are sure that it will behave exactly the same on acceptance and
        production! Anyone who has dealt with platform-specific issues due to minuscule differences, which are often
        difficult to debug, can testify what a blessing this is.</p>

    <p>Furthermore, Docker in combination with Kubernetes (and any of its offspring such as Openshift) allows for easy
        scaling. There are settings available for automated scaling based on current needs or expected peaks. For
        example, scale up extra Docker containers when >80% CPU threshold has been exceeded or during the period that
        the application is commonly used a lot more. Scaling down works the same way and all this can be configured
        through a simple yaml file.</p>

    <p>So what does this have to do with the DevOps environment? In many older DevOps systems, it is common to not only
        backup essential company assets (such as deployed artifacts to Nexus/Artifactory/...), but the whole DevOps
        environment as well. This makes sense since a sudden loss of these tools will severely cripple the development
        and release process. This in turn will cost the company a lot. But we only know that these backups work on the
        configuration of that machine. We aren't guaranteed that the backups will work immediately if restored on
        another machine unless special care is taken that it is an exact duplicate (this is harder than it sounds!).</p>

    <p>If instead we use Docker images, then we can put the configurations as Dockerfiles
        into a version control system such as git. The benefits are known to all: it is easy to rollback
        to a prior setting if a new implementation is causing issues which can't be immediately resolved. Docker images
        can be pulled into any system and will function the same.</p>

    <h3>Orchestrate with Docker Compose</h3>

    <p>In this section I will show how the DevOps environment can be setup with Docker. I use Docker Compose to
        orchestrate the different containers. </p>

    <p>I should note that I had started out using Windows as my DevOps machine (against my better judgement).
        Windows has provided big leaps in support for Docker and Linux commands through the WSL2 implementation of
        Docker Desktop, but there are still some important features missing. I found myself working around the
        limitations of Windows quite often before I eventually admitted defeat and switched over to a Linux host. This
        immediately proved my setup to be working though, since all I had to do was checkout my DevOps git repository
        (and copy my passwords/credentials that I don't check into git obviously)
        and run <code class="github-code">docker compose up</code>!</p>

    <p>Here is an example <code class="github-code">docker-compose.yml</code> that I use to setup a Nexus, Jenkins and
        Nginx container.</p>

    <pre><code [languages]="['yaml']" [highlight]="'version: \'3.7\'
services:
  nexus:
    build: ./nexus/.
    image: bytepact/nexus
    container_name: nexus
    expose:
      - 8081
    volumes:
      - nexusdata:/nexus-data
    networks:
      - devops-network
  jenkins:
    build: ./jenkins/.
    image: bytepact/jenkins
    container_name: jenkins
    env_file:
      - jenkins/secrets/user-credentials.env
    secrets:
      - bitbucketSshKey
    expose:
      - 8080
    depends_on:
      - nexus
    volumes:
      - jenkinsdata:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - devops-network
  nginx:
    image: nginx:1.19.5
    container_name: nginx
    ports:
      - 80:80
      - 443:443
    depends_on:
      - nexus
      - jenkins
    volumes:
      - ./nginx/site_content:/usr/share/nginx/html
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
    networks:
      - devops-network
volumes:
  nexusdata:
  jenkinsdata:
secrets:
  bitbucketSshKey:
    file: ./jenkins/secrets/bitbucket/ssh_private_key
networks:
  devops-network:'">
    </code></pre>

    <p>There are not as many things going on as it would seem at first glance. The Docker image is defined, either from
        a local Dockerfile or an external image on Dockerhub. Then there are the ports, volumes and
        secrets/credentials.</p>

    <p>The ports are easy to explain. Jenkins and Nexus are configured to <b>expose</b> their HTTP ports. Expose means
        that the docker containers have their ports made accessible to the Docker network, but not to the host. In this
        setup we do not want to access these containers through localhost directly. Instead Nginx will port forward its
        HTTP and HTTPS ports to the hosts' localhost. This is also the reason why HTTPS is not necessary for Jenkins and
        Nexus. Everything passes through Nginx, so we only need to ensure that those incoming urls are encrypted.</p>

    <p>The volumes are quite self-explanatory. We map the data to/from the host to persist container data beyond the
        containers' lifespan. The main thing of note is perhaps
        <code class="github-code">/var/run/docker.sock:/var/run/docker.sock</code>. This is required to make Docker
        available within the Jenkins container to run Docker agents within Jenkins pipelines. It will use the host
        Docker daemon within the container, so any images pulled within the container will be available from the host as
        well. This proves useful since images do not need to be pulled again each time the container is restarted.</p>

    <p>Finally, credentials of any kinds should not be hardcoded into these configuration files and definitely not
        checked into git. For that, you can use <code class="github-code">env_file</code> to provide a file with
        environment properties (often passwords). There's another mechanism I use to retrieve a private SSH key: Docker
        secrets. The contents of such a key is much larger than that of a normal password, so I prefer to keep them in a
        separate file. In the above example, the private SSH key is stored in a file named <i>bitbucketSshKey</i>. You
        can access them in the Docker container in the following way:</p>

    <pre><code [languages]="['yaml']" [highlight]="'docker exec -it jenkins cat /run/secrets/bitbucketSshKey'">
    </code></pre>

    <h3>Nginx</h3>

    <p>The setup for Nginx is quite straight-forward. The volume I mapped for the <b>site_content</b> is merely a
        directory with html pages to display 200 OK and unhappy path messages. More interesting is the <code
            class="github-code">nginx.conf</code>.</p>

    <pre><code [languages]="['text']" [highlight]="'// worker configuration

http {
    upstream docker-jenkins {
        server jenkins:8080;
    }
    upstream docker-nexus {
        server nexus:8081;
    }

    // proxy headers

    server {
        listen       80;
        server_name  global.dns nginx.global.dns;

        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
        }

        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/share/nginx/html;
        }
    }

    server {
        server_name  jenkins.homenetwork.dns;

        location / {
            proxy_pass http://docker-jenkins;
        }
    }

    server {
        server_name  nexus.homenetwork.dns;

        location / {
            proxy_pass http://docker-nexus;
        }
    }
}'">
    </code></pre>

    <p>Given this setup the applications can be accessed through <code
        class="github-code">http://[app].homenetwork.dns</code>, such as <code class="github-code">http://jenkins.homenetwork.dns</code>.
        In this example Nginx is configured with HTTP, but it is easily converted to use HTTPS (and it should!). The
        Jenkins and Nexus containers are available through their container names. All client computers need to configure
        their <code class="github-code">hosts</code> file to map these addresses to the IP of the host of these
        containers. The host computer itself simply maps to localhost of course.</p>

    <pre><code [languages]="['text']" [highlight]="'127.0.0.1 nginx.homenetwork.dns
127.0.0.1 jenkins.homenetwork.dns
127.0.0.1 nexus.homenetwork.dns'">
    </code></pre>

    <h3>Jenkins</h3>

    <p>In this section I will show how to setup a completely initialized Jenkins environment with users, credentials,
        pipelines, global settings, etc without having to setup any of these manually! That means everything is
        available if you were to run it on a new machine. This follows the principle of <i>code as configuration</i>.
    </p>

    <p>The setup here was a bit more complicated and admittedly took much more time than if I hadsimply installed
        Jenkins. This is partially due to a low number of working examples at this time of writing.
        But we are looking for long term gains! And this is simply fun and useful to have once you got it working.</p>

    <p>Let's start with the Dockerfile:</p>

    <pre><code [languages]="['text']" [highlight]="'FROM jenkins/jenkins:2.263.1-lts-jdk11
MAINTAINER me@example.com

USER root
# Install the stuff you need

USER jenkins

# Skip initial setup
ENV JAVA_OPTS -Djenkins.install.runSetupWizard=false
ENV CASC_JENKINS_CONFIG /var/jenkins_home/userContent/casc.yaml

COPY config/locale.xml /var/jenkins_home/locale.xml
COPY config/plugins.txt /usr/share/jenkins/ref/plugins.txt
RUN jenkins-plugin-cli -f /usr/share/jenkins/ref/plugins.txt
COPY config/casc.yaml /var/jenkins_home/userContent/casc.yaml
COPY config/mavenSettings.xml /var/jenkins_home/userContent/settings.xml
COPY jobs/project_seed/config.xml /usr/share/jenkins/ref/jobs/project_seed/config.xml
ADD pipelines /usr/share/jenkins/ref/jobs/project_seed/workspace/'">
    </code></pre>

    <p>This Dockerfile does a bunch of things. First it disables the setup wizard, because we are going to automate
        everything. A <code class="github-code">locale.xml</code> is copied over to set the system language and a list
        of plugins gets moved to <code class="github-code">/usr/share/jenkins/ref/*</code>. These plugins will be
        installed on initialization of the Jenkins container. Note that the files under <code class="github-code">/usr/share/jenkins/ref/*</code>
        <a href="https://github.com/jenkinsci/docker/blob/master/README.md"> will automatically be picked up by the
            plugins to be initialized</a>.</p>

    <p>Next, <code class="github-code">casc.yaml</code> is copied over to the container. It is easier to simply
        <a href="https://github.com/jenkinsci/configuration-as-code-plugin/blob/master/README.md">link you to the JCasC
            plugin</a>, but to explain it in a nutshell: this is the plugin that handles the automatic configuration of
        users, credentials and more. Describe what you want in the yaml file and it will be added during initialization.
        An example of such a <code class="github-code">casc.yaml</code> looks like this:</p>

    <pre><code [languages]="['text']" [highlight]="'jenkins:
  securityRealm:
    local:
      allowsSignup: false
      users:
        - id: admin
          password: ${JENKINS_ADMIN_PASSWORD}
        - id: git
          password: ${JENKINS_GIT_PASSWORD}
credentials:
  system:
    domainCredentials:
      - credentials:
          - basicSSHUserPrivateKey:
              id: \'unique_id\'
              scope: USER
              username: Jenkins
              description: \'Bitbucket SSH key\'
              passphrase: ${BITBUCKET_SSH_PASSPHRASE}
              privateKeySource:
                directEntry:
                  privateKey: ${readFile:/run/secrets/bitbucketSshKey}
unclassified:
  globalConfigFiles:
    configs:
      - globalMavenSettings:
          id: \'unique_id\'
          content: ${readFile:/var/jenkins_home/userContent/settings.xml}'">
    </code></pre>

    <p>Remember the <code class="github-code">env.file</code> and Docker secret we added in the <code
        class="github-code">docker-compose.yml</code>? Here they get accessed to fill in the correct credentials! The
        following are added in this example alone: two users, a global SSH credential and maven settings (ie. for
        download/upload to Nexus). Note: a few more things will need to be added to satisfy Jenkins' security issues,
        but I am keeping this compact for tutorial purposes.</p>

    <p>To quickly go over the remaining items in the Dockerfile:</p>
    <ul>
        <li><code class="github-code">mavenSettings.xml</code>: We have already seen this being used in <code
            class="github-code">casc.yaml</code>. Just make sure you don't put hardcoded credentials in the maven
            settings! It can access the environment properties from <code class="github-code">env.file</code>.
        </li>
        <li><code class="github-code">jobs/project_seed/config.xml</code>: Creates a job that is intended to be used to
            spawn a project folder with predefined pipelines.
        </li>
        <li><code class="github-code">pipelines/*</code>: This directory contains the pipelines that are referenced by
            the seed job (which was spawned by the <code class="github-code">config.xml</code>).
        </li>
    </ul>

    <p>Any jobs that are added manually afterwards are persisted on the host on volume <code class="github-code">jenkinsdata</code>.
        Schedule regular backups of those jobs (in the <code class="github-code">job/</code> directory) if it is crucial
        that they are kept.</p>

    <h3>Nexus</h3>

    <p><a href="https://github.com/AdaptiveConsulting/nexus-casc-plugin">Nexus has similar options as Jenkins, but it
        still seems to be in development.</a> For this, there is a secondary approach that requires slightly more work.
        Nexus offers scripts that you can send through REST calls.
        <a href="https://github.com/sonatype-nexus-community/nexus-scripting-examples">The examples on Nexus</a> are
        good enough to start from and modify as you see fit. In the Dockerfile, copy <code class="github-code">nexus.properties</code>
        to the container to enable scripting first:</p>

    <pre><code [languages]="['text']" [highlight]="'// Dockerfile
...
COPY config/nexus.properties nexus-data/etc/nexus.properties'">
    </code></pre>

    <pre><code [languages]="['text']" [highlight]="'// nexus.properties
nexus.scripts.allowCreation=true'">
    </code></pre>

    <p>Execute the <code class="github-code">provision.sh</code> script to carry out all the POST commands that you
        added. Then as a security step, enter the Nexus container (<code class="github-code">docker exec -u 0 -it nexus
            bash</code>) and edit <code class="github-code">/nexus-data/etc/nexus.properties</code>:</p>

    <pre><code [languages]="['text']" [highlight]="'nexus.scripts.allowCreation=false'">
    </code></pre>

    <h3>Conclusion</h3>

    <p>In this setup we have seen how to predefine all the configuration we need that we would normally do manually
        (clicking through the GUI). By automating it we can simply run <code class="github-code">docker-compose
            up</code> and everything will be there! This is especially useful if you are in a situation where you have
        to reconfigure these settings over and over. The downside is that the configuration will likely take longer than
        a manual setup. Since I am developing by myself, this was a huge overkill for me. But I learned from my mistakes
        and enjoyed setting it up. I am rest assured that if I need to setup my DevOps environment on a new machine,
        everything will still be tailored to my needs out of the box!</p>
</app-blog-post>
